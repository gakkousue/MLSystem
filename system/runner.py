# system/runner.py
import sys
import os
import json
import time
import subprocess
import shutil
import glob
import signal
from queue_manager import QueueManager

# PIDãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ—ãƒ­ã‚»ã‚¹ã®åæœ­ï¼‰
PID_FILE = os.path.join("queue", "runner.pid")

def setup_dirs(root):
    dirs = {
        "pending": os.path.join(root, "pending"),
        "running": os.path.join(root, "running"),
        "finished": os.path.join(root, "finished"),
        "failed": os.path.join(root, "failed"),
        "logs": os.path.join(root, "logs"),  # ãƒ­ã‚°ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
    }
    for d in dirs.values():
        os.makedirs(d, exist_ok=True)
    return dirs

class Runner:
    def __init__(self):
        self.current_process = None
        self.queue_root = os.path.join(os.getcwd(), "queue")
        self.dirs = setup_dirs(self.queue_root)
        self.running = True
        self.qm = QueueManager() # QueueManagerã‚’åˆæœŸåŒ–

        # ã‚·ã‚°ãƒŠãƒ«ï¼ˆåœæ­¢å‘½ä»¤ï¼‰ã‚’å—ã‘å–ã‚‹è¨­å®š
        signal.signal(signal.SIGTERM, self.handle_signal)
        signal.signal(signal.SIGINT, self.handle_signal)

    def handle_signal(self, signum, frame):
        """åœæ­¢å‘½ä»¤ãŒæ¥ãŸã‚‰å®Ÿè¡Œã•ã‚Œã‚‹"""
        print(f"ğŸ›‘ Signal {signum} received. Stopping...")
        self.running = False
        
        # å­ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆå­¦ç¿’ï¼‰ãŒå‹•ã„ã¦ã„ãŸã‚‰é“é€£ã‚Œã«ã™ã‚‹
        if self.current_process and self.current_process.poll() is None:
            print("Killing current training process...")
            self.current_process.terminate()
            try:
                self.current_process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                self.current_process.kill()
        
        self.cleanup()
        sys.exit(0)

    def cleanup(self):
        """çµ‚äº†æ™‚ã®å¾Œå§‹æœ«"""
        if os.path.exists(PID_FILE):
            try:
                os.remove(PID_FILE)
            except:
                pass

    def run(self):
        # 1. èµ·å‹•æ™‚ã«PIDï¼ˆåæœ­ï¼‰ã‚’ä¿å­˜
        with open(PID_FILE, "w") as f:
            f.write(str(os.getpid()))

        print(f"ğŸ‘· Runner started. PID: {os.getpid()}")

        try:
            while self.running:
                # 1. QueueManagerã‹ã‚‰æ¬¡ã®ã‚¸ãƒ§ãƒ–IDã‚’å–å¾— (ãƒªã‚¹ãƒˆç®¡ç†)
                job_id = self.qm.pop()
                
                if not job_id:
                    # ã‚¸ãƒ§ãƒ–ãŒãªã„å ´åˆã¯çµ‚äº†
                    print("âœ… No more jobs in queue list. Exiting.")
                    break

                # 2. ã‚¸ãƒ§ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š
                # ãƒ•ã‚¡ã‚¤ãƒ«åã¯ job_{id}.json ã¨æ±ºã¾ã£ã¦ã„ã‚‹
                pending_path = os.path.join(self.dirs["pending"], f"job_{job_id}.json")
                
                if not os.path.exists(pending_path):
                    print(f"âš ï¸ Job file not found for ID: {job_id}")
                    continue

                self.process_job(pending_path, job_id)
                
        finally:
            self.cleanup()

    def process_job(self, job_path, job_id):
        filename = os.path.basename(job_path)
        running_path = os.path.join(self.dirs["running"], filename)
        
        # pending -> running ç§»å‹•
        try:
            shutil.move(job_path, running_path)
        except FileNotFoundError:
            return # ä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒå–ã£ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

        with open(running_path, "r") as f:
            job_data = json.load(f)

        task_type = job_data.get("task_type", "train")
        print(f"ğŸš€ Processing: {job_id} (Type: {task_type})")

        # å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã®åˆ†å²
        if task_type == "plot":
            # execute_plot.py ã‚’ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦å®Ÿè¡Œ
            # å¼•æ•°ã¨ã—ã¦ã‚¸ãƒ§ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ¸¡ã™
            script_path = os.path.join("system", "execute_plot.py")
            # ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã™ã§ã« running ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€running_path ã‚’æ¸¡ã™
            cmd = [sys.executable, script_path, running_path]
        else:
            # é€šå¸¸ã®å­¦ç¿’ (execute_train.py)
            cmd = [sys.executable, "system/execute_train.py"] + job_data["args"]
        
        start_time = time.time()
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹è¨­å®š
        log_filename = f"job_{job_id}.log"
        log_path = os.path.join(self.dirs["logs"], log_filename)

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦ã€æ¨™æº–å‡ºåŠ›ãƒ»æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’æ›¸ãè¾¼ã‚€
        with open(log_path, "w", encoding="utf-8") as log_file:
            # ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä¿æŒã—ã¦ãŠãï¼ˆåœæ­¢æ™‚ã«é“é€£ã‚Œã«ã™ã‚‹ãŸã‚ï¼‰
            # stdout, stderrã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
            self.current_process = subprocess.Popen(cmd, stdout=log_file, stderr=subprocess.STDOUT)
            
            # çµ‚äº†å¾…ã¡
            return_code = self.current_process.wait()
        
        duration = time.time() - start_time
        self.current_process = None # çµ‚ã‚ã£ãŸã‚‰ã‚¯ãƒªã‚¢

        # çµæœç§»å‹•
        if return_code == 0:
            dest = os.path.join(self.dirs["finished"], filename)
            status = "finished"
            error_msg = None
        else:
            dest = os.path.join(self.dirs["failed"], filename)
            status = "failed"
            # å¤±æ•—æ™‚ã¯ãƒ­ã‚°ã®æœ€å¾Œã®æ–¹ã‚’èª­ã¿å–ã£ã¦ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å–å¾—ã™ã‚‹
            error_msg = self._tail_log(log_path)

        shutil.move(running_path, dest)
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
        with open(dest, "r+") as f:
            data = json.load(f)
            data["status"] = status
            data["duration"] = duration
            data["finished_at"] = time.time()
            data["log_file"] = log_path
            if error_msg:
                data["error_message"] = error_msg
            
            f.seek(0)
            json.dump(data, f, indent=4)
            f.truncate()

        # æƒé™¤: finishedãƒ•ã‚©ãƒ«ãƒ€ãŒæºœã¾ã‚Šã™ããªã„ã‚ˆã†ã«å¤ã„ã‚‚ã®ã‚’å‰Šé™¤ (æœ€æ–°20ä»¶ä¿æŒ)
        if status == "finished":
            self.cleanup_old_jobs(self.dirs["finished"], keep_limit=20)
            # æˆåŠŸã—ãŸå ´åˆã€å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æƒé™¤ã—ã¦ã‚‚è‰¯ã„ãŒã€ä»Šå›ã¯æ®‹ã™æ–¹é‡ã¨ã™ã‚‹
            
    def _tail_log(self, path, lines=20):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ«å°¾ã‚’å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼"""
        try:
            with open(path, "r", encoding="utf-8", errors="ignore") as f:
                # ç°¡æ˜“çš„ãªå®Ÿè£…: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã‘ã‚Œã°å…¨éƒ¨èª­ã‚€
                content = f.readlines()
                return "".join(content[-lines:])
        except Exception:
            return "Could not read log file."

    def cleanup_old_jobs(self, target_dir, keep_limit=20):
        """æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€å†…ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤šã™ãã‚‹å ´åˆã€å¤ã„é †ã«å‰Šé™¤ã™ã‚‹"""
        try:
            files = glob.glob(os.path.join(target_dir, "*.json"))
            if len(files) <= keep_limit:
                return

            # æ›´æ–°æ—¥æ™‚ãŒå¤ã„é †ã«ã‚½ãƒ¼ãƒˆ
            files.sort(key=os.path.getmtime)
            
            # å‰Šé™¤å¯¾è±¡: å…¨ä½“æ•° - æ®‹ã™æ•°
            num_to_delete = len(files) - keep_limit
            
            for f in files[:num_to_delete]:
                try:
                    os.remove(f)
                    print(f"ğŸ§¹ Auto-cleaned old log: {os.path.basename(f)}")
                except Exception as e:
                    print(f"âš ï¸ Failed to delete {f}: {e}")
        except Exception:
            pass

if __name__ == "__main__":
    runner = Runner()
    runner.run()