# 実験管理システム 設計書 (Experiment Management System Design Document) Ver 3.0

## 1. システム概要
本システムは、深層学習における実験プロセス（設定、学習、中断・再開、記録）を効率化するためのフレームワークである。
設定の再現性を担保しつつ、バックグラウンドでのジョブ順次実行を容易にすることを目的とする。

### コア・コンセプト
1.  **Deterministic Configuration（設定の決定論的管理）**
    *   設定値（ハイパーパラメータ）が一意であれば、必ず同じ「実験ID（ハッシュ値）」が発行される。
    *   これにより、設定を変更せずに再実行した場合は「続きから再開（Resume）」、設定を変えた場合は「新規実験」として自動的に振り分けられる。
2.  **Adapter Pattern Integration（アダプターによる柔軟な結合）**
    *   **Model（調理）** と **Dataset（素材）** を直接結合せず、**Adapter（橋渡し）** を介在させる。
    *   Adapterがデータの整形ルール（Transform）とモデル構築情報を提供することで、同じデータセットを異なるモデル（画像認識、GNN等）で再利用可能にする。
3.  **Transient Background Execution（一時的なバックグラウンド実行）**
    *   常駐サービス（デーモン）を使用せず、必要な時だけ起動し、ジョブがなくなれば自動終了する「Runner」方式を採用。
4.  **Separation of Concerns（関心の分離）**
    *   **Dataset (`definitions/datasets/`)**: データの保持、分割、Augmentation、生データの可視化。
    *   **Adapter (`definitions/models/.../adapters/`)**: データの整形ルール指定、モデル引数の生成、整形後データの可視化。
    *   **Model (`definitions/models/`)**: ネットワーク構築、学習ループ定義、学習結果の可視化。
    *   **System (`system/`)**: 実行エンジン、GUI、キュー管理。

---

## 2. 機能要件と実現方法

### ① 学習の途中再開 (Auto-Resume)
*   **目的**: 中断（Stop操作やエラー）の後、学習済みエポックから計算を再開したい。
*   **実装**:
    *   設定ハッシュに基づき保存ディレクトリを固定化（`output/experiments/{hash_id}`）。
    *   `system/train.py` 起動時、ディレクトリ内の `last.ckpt` があれば自動的にロードして再開。

### ② Adapterによる動的結合と検証 (Dynamic Binding & Verification)
*   **目的**: データの加工前・加工後・学習結果をそれぞれ確認し、モデルとデータのミスマッチを防ぐ。
*   **実装**:
    *   **Dependency Injection**: Adapterが指定した変換関数（Transform）をDatasetに注入し、Dataset内で実行する。
    *   **3段階可視化 (3-Phase Plotting)**:
        1.  **Raw Data Plot**: Datasetが「加工前の生データ」を描画（例: 元画像）。
        2.  **Transformed Plot**: Adapterが「モデル入力直前のデータ」を描画（例: 正規化済みTensor）。
        3.  **Result Plot**: Modelが「学習後の結果」を描画（例: 混同行列）。
    *   **Config連動**: Adapterの設定で対象Datasetを指定し、GUI操作時の選択ミスを防止する。

### ③ GUIモニタリング (Experiment Cockpit)
*   **目的**: 実験の設定、キューへの追加、現在の実行状況の監視を一元管理する。
*   **実装**:
    *   **階層的選択UI**: Model → Adapter → Dataset の順で選択。Adapter選択時に適切なDatasetを自動ロックする。
    *   **Job Queue Monitor**: `queue/` フォルダ内のJSONを定期スキャンし、ジョブ状態をリスト表示。
    *   **非同期操作**: GUIをフリーズさせずにRunnerプロセスの起動・停止を制御。

---

## 3. ディレクトリ構成図

```text
project_root/
│
├── definitions/                  # 【ユーザー実装領域】
│   ├── datasets/
│   │   └── {dataset_name}/       # データセット定義
│   │       ├── config.py         # 設定 (val_ratio, data_dir等)
│   │       ├── datamodule.py     # データ保持・分割・Augmentation
│   │       └── plots.py          # [Phase 1] 生データの可視化
│   │
│   └── models/
│       └── {model_name}/         # モデル定義
│           ├── config.py         # 設定 (lr, network_params等)
│           ├── model.py          # ネットワーク構築 (Adapterの指示に従う)
│           ├── plots.py          # [Phase 3] 学習結果の可視化
│           │
│           └── adapters/         # ★新設: アダプター領域
│               └── {adapter_name}/
│                   ├── config.py     # 設定 (対象Dataset指定, リサイズ等)
│                   ├── adapter.py    # 変換ロジック指定 & 引数生成
│                   └── plot.py       # [Phase 2] 変換後データの可視化
│
├── system/                       # 【システム基盤領域】
│   ├── train.py              # 学習実行エンジン (Hydra + Lightning)
│   ├── gui.py                # デスクトップGUIアプリ (設定 & 監視)
│   ├── visualize.py          # 実験結果のロード・分析用ユーティリティ
│   ├── runner.py             # ジョブ実行ランナー
│   ├── submit.py             # ジョブ登録
│   └── hashing.py            # 設定ハッシュ計算 (Adapter含む)
│
├── output/                       # 【実験結果領域】
│   └── experiments/
│       └── {hash_id}/        # 実験ごとの出力フォルダ
│
└── queue/                        # 【ジョブ管理領域】
    ├── pending/              # 待ち行列
    ├── running/              # 実行中
    └── ...
```

---

## 4. データフローと処理プロセス

### A. ジョブ登録フロー (Add to Queue)
1.  **Model選択**: ユーザーがGUIでモデルを選択。
2.  **Adapter選択**: モデルに対応するAdapterを選択。
3.  **Dataset自動固定**: 選択されたAdapterのConfigに基づき、Datasetが自動選択・ロックされる。
4.  **登録**: 「ADD TO QUEUE」押下により、`model`, `adapter`, `dataset` の3要素を含むJSONが `queue/pending/` に作成される。

### B. 実行・結合フロー (Execution Pipeline)
`system/train.py` は以下の順序でモジュールを結合し、学習を開始する。

1.  **Adapter Load**: 指定されたAdapterをロードし、`input_transform`（整形ルール）を取得。
2.  **Dataset Init**: `input_transform` をDatasetに渡し、初期化。
    *   *Plot Phase 1*: Datasetが生データを可視化保存。
3.  **Setup**: Datasetがデータをロード・分割し、Augmentationと整形ルールをパイプライン化。
    *   *Plot Phase 2*: Adapterがパイプライン通過後のデータを可視化保存。
4.  **Meta Info Transfer**: Datasetのメタ情報（クラス数、ch数など）をAdapterに渡す。
5.  **Model Init**: Adapterが生成した初期化引数（`model_kwargs`）を用いてModelを構築。
6.  **Train**: 学習開始。
    *   *Plot Phase 3*: 学習完了後、Modelが結果を可視化保存。

---

## 5. 開発者向けガイド

| 目的           | 編集ファイル                                      | 内容                                                     |
| :----------- | :------------------------------------------ | :----------------------------------------------------- |
| **新規モデル追加**  | `definitions/models/{name}/`                | `model.py` (構造), `config.py` (学習率等), `adapters/` を作成。  |
| **新規データ対応**  | `definitions/models/{name}/adapters/{new}/` | 新しいデータセット形式に合わせるための変換ロジック (`adapter.py`) と設定を作成。       |
| **データセット追加** | `definitions/datasets/{name}/`              | `datamodule.py` でデータのロードと `BaseDataset` への格納を実装。       |
| **可視化の追加**   | 各階層の `plots.py`                             | 生データ(Dataset)、入力テンソル(Adapter)、結果(Model)のいずれかに可視化関数を追加。 |
| **パラメータ追加**  | 各 `config.py`                               | 辞書にキーを追加。GUI・ハッシュ計算に自動反映。                              |